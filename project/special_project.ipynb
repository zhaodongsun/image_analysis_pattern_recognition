{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Special project\n",
    "\n",
    "**Group members:**\n",
    "    1- first name and last name,\n",
    "    2- first name and last name,\n",
    "    3- first name and last name\n",
    "\n",
    "**Due date:** 30.05.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Please find the description of this special project via [this link].\n",
    "\n",
    "[this link]: https://github.com/LTS5/iapr-2019/blob/master/project/special_project_description.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding varroas by segmentation\n",
    "Add your implementation for ''**detect_by_segmentation**'' function. Please make sure the input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_segmentation(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    img = skimage.color.rgb2gray(img) # convert to the grayscale image\n",
    "    img = img<0.3 # threshold the image\n",
    "    img = morphology.binary_opening(img, np.ones((6,6))) # openning to eliminate small areas\n",
    "    label_img = skimage.measure.label(img) # label all the connected area\n",
    "    prop = skimage.measure.regionprops(label_img)\n",
    "    bboxes = []\n",
    "    for p in prop:\n",
    "        bboxes.append([p['bbox'][1], p['bbox'][0], p['bbox'][3]-p['bbox'][1], p['bbox'][2]-p['bbox'][0]])\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_over_union(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3]) # intersection rectangle\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1) #the area of intersection rectangle\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1) #the area of both the prediction and ground-truth\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea) # the intersection over union \n",
    "    return iou\n",
    "\n",
    "def cal_iou(pred_bboxes, gt_bboxes):\n",
    "    gt_bboxes_new = []\n",
    "    for gt_bbox in gt_bboxes:\n",
    "        gt_bboxes_new.append([gt_bbox[0], gt_bbox[1], gt_bbox[0] + gt_bbox[2], gt_bbox[1] + gt_bbox[3]]) # transform the (x, y, width, heigth) to (x_min, y_min, x_max, y_max) for ground truth\n",
    "    \n",
    "    ious = []\n",
    "    gt_candidate_set = []\n",
    "    for j, pred_bbox in enumerate(pred_bboxes):\n",
    "        pre_bbox = (pred_bbox[0], pred_bbox[1], pred_bbox[0] + pred_bbox[2], pred_bbox[1] + pred_bbox[3]) # transform the (x, y, width, heigth) to (x_min, y_min, x_max, y_max)\n",
    "        iou = 0\n",
    "        gt_i = -1 # -1 means the candinate not corresponding to any ground truth\n",
    "        for i, gt_bbox in enumerate(gt_bboxes_new):\n",
    "            new_iou = iter_over_union(gt_bbox, pre_bbox) # use the brute force method to calculate the largest IOU for each predicted box\n",
    "            if new_iou > iou:\n",
    "                iou = new_iou\n",
    "                gt_i = i\n",
    "        gt_candidate_set.append((gt_i,j))\n",
    "        ious.append(iou)\n",
    "    return ious,gt_candidate_set\n",
    "\n",
    "def precision_recall_f1(T, ious,  gt_candidate_set, num_gt_bbox):\n",
    "    # T is the threshols for true positive samples\n",
    "    # ious is the list constaining all the ious\n",
    "    # gt_candidate_set is the gt and candidate pair set\n",
    "    # num_gt_bbox is the number of ground truth bbox\n",
    "    total = len(ious)\n",
    "    ious = np.array(ious)\n",
    "    tp = np.sum(ious>T) # the number of true positive samples\n",
    "    fp = np.sum(ious<=T) # the number of false positive samples\n",
    "\n",
    "    gt_index = [] # use loop to fill the gt index in the list\n",
    "    for iou, (i, j) in zip(ious.tolist(), gt_candidate_set):\n",
    "        if (not i in gt_index) and (i!=-1) and (iou>=T):\n",
    "            gt_index.append(i) # add the gt index that can correspond to our predicted bbox\n",
    "    fn = num_gt_bbox - len(gt_index) # the number of false negative\n",
    "    \n",
    "    precision = tp / (tp+fp) if tp!=0 else 0\n",
    "    recall = tp / (tp+fn) if tp!=0 else 0\n",
    "    f1 = 2*precision*recall/(precision+recall) if precision*recall!=0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluation(T, pred_bboxes, gt_bboxes):\n",
    "    ious, gt_candidate_set = cal_iou(pred_bboxes, gt_bboxes)\n",
    "    precision, recall, f1 = precision_recall_f1(T, ious,  gt_candidate_set, len(gt_bboxes))\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.16 Recall: 0.83, F1: 0.26\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.03 Recall: 0.65, F1: 0.06\n",
      "Precision: 0.01 Recall: 1.00, F1: 0.01\n",
      "Precision: 0.04 Recall: 1.00, F1: 0.08\n",
      "Precision: 0.27 Recall: 0.40, F1: 0.32\n",
      "Precision: 0.04 Recall: 1.00, F1: 0.08\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.11 Recall: 0.90, F1: 0.19\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.03 Recall: 1.00, F1: 0.05\n",
      "Precision: 0.05 Recall: 0.50, F1: 0.09\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.06 Recall: 1.00, F1: 0.10\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.01 Recall: 0.75, F1: 0.02\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.02 Recall: 0.88, F1: 0.03\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.09 Recall: 0.92, F1: 0.16\n",
      "Precision: 0.11 Recall: 0.33, F1: 0.16\n",
      "Precision: 0.01 Recall: 1.00, F1: 0.03\n",
      "Precision: 0.02 Recall: 1.00, F1: 0.04\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.01 Recall: 1.00, F1: 0.02\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.03 Recall: 1.00, F1: 0.07\n",
      "Precision: 0.06 Recall: 0.18, F1: 0.10\n",
      "Precision: 0.04 Recall: 1.00, F1: 0.07\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 1.00, F1: 0.01\n",
      "Precision: 0.27 Recall: 0.30, F1: 0.29\n",
      "Precision: 0.02 Recall: 0.69, F1: 0.03\n",
      "Precision: 0.04 Recall: 0.57, F1: 0.07\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.00 Recall: 0.00, F1: 0.00\n",
      "Precision: 0.01 Recall: 1.00, F1: 0.02\n",
      "Precision: 0.01 Recall: 1.00, F1: 0.03\n",
      "Precision: 0.00 Recall: 1.00, F1: 0.01\n",
      "Precision: 0.02 Recall: 1.00, F1: 0.04\n",
      "Precision: 0.22 Recall: 0.67, F1: 0.33\n",
      "Precision: 0.13 Recall: 1.00, F1: 0.23\n",
      "Average Precision: 0.04 Average Recall: 0.49, Average F1: 0.06\n"
     ]
    }
   ],
   "source": [
    "T = 0.3\n",
    "file_names = pd.read_csv('./project-data/test.txt',header=None)[0].tolist()\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for n in file_names:\n",
    "    img = skimage.io.imread('./project-data/images/test/'+n+'.jpg')\n",
    "    gt_bboxes = parse_file('./project-data/annotations/test/'+n+'.xml')\n",
    "    gt_bboxes = [gb['bbox'] for gb in gt_bboxes]\n",
    "    pred_bboxes = detect_by_segmentation(img)\n",
    "    precision, recall, f1 = evaluation(T, pred_bboxes, gt_bboxes)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    print('Precision: %.2f Recall: %.2f, F1: %.2f'%(precision, recall, f1))\n",
    "print('Average Precision: %.2f Average Recall: %.2f, Average F1: %.2f'%(np.mean(precisions), np.mean(recalls), np.mean(f1s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement your first detector\n",
    "\n",
    "Write your function(s) for the second part. Feel free to change the name of the function and add your additional functions, but please make sure their input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_method_1(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using MLP and CNNs\n",
    "\n",
    "Add your implementation for the thrid part. Feel free to add your desirable functions, but please make sure you have proper functions for the final detection, where their input and output follows the same format as the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You can generate a json submission file by using the function ''**generate_pred_json**''. This prediction file can be uploaded online for evaluation (Please refer to section 3 of the project description for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_pred_json(data, tag='baseline'):\n",
    "    '''\n",
    "    Input\n",
    "    - data: Is a dictionary d, such that:\n",
    "          d = { \n",
    "              \"ID_1\": [], \n",
    "              \"ID_2\": [[x_21, y_21, w_21, h_21], [x_22, y_22, w_22, h_22]], \n",
    "              ... \n",
    "              \"ID_i\": [[x_i1, y_i1, w_i1, h_i1], ..., [x_iJ, y_iJ, w_iJ, h_iJ]],\n",
    "              ... \n",
    "              \"ID_N\": [[x_N1, y_N1, w_N1, h_N1]],\n",
    "          }\n",
    "          where ID is the string id of the image (e.i. 5a05e86fa07d56baef59b1cb_32.00px_1) and the value the Kx4 \n",
    "          array of intergers for the K predicted bounding boxes (e.g. [[170, 120, 15, 15]])\n",
    "    - tag: (optional) string that will be added to the name of the json file.\n",
    "    Output\n",
    "      Create a json file, \"prediction_[tag].json\", conatining the prediction to EvalAI format.\n",
    "    '''\n",
    "    unvalid_key = []\n",
    "    _data = data.copy()\n",
    "    for key, value in _data.items():\n",
    "        try:\n",
    "            # Try to convert to numpy array and cast as closest int\n",
    "            print(key)\n",
    "            v = np.around(np.array(value)).astype(int)\n",
    "            # Check is it is a 2d array with 4 columns (x,y,w,h)\n",
    "            if v.ndim != 2 or v.shape[1] != 4:\n",
    "                unvalid_key.append(key)\n",
    "            # Id must be a string\n",
    "            if not isinstance(key, str):\n",
    "                unvalid_key.append(key)\n",
    "            _data[key] = v.tolist()\n",
    "        # Deal with not consistant array size and empty predictions\n",
    "        except (ValueError, TypeError):\n",
    "            unvalid_key.append(key)\n",
    "    # Remove unvalid key from dictionnary\n",
    "    for key in unvalid_key: del _data[key]\n",
    "    \n",
    "    with open('prediction_{}.json'.format(tag), 'w') as outfile:\n",
    "        json.dump(_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
